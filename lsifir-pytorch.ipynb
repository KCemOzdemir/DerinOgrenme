{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as n\nimport torch.nn.functional as F\nimport torch.utils.data\nimport torch.optim as optim\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport time","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_images(path,num_img):\n    array = np.zeros([num_img,64*32])\n    i = 0\n    for img in os.listdir(path):\n        img_path = path + \"//\" + img\n        img = Image.open(img_path, mode=\"r\")\n        data = np.asarray(img,dtype = \"uint8\")\n        data = data.flatten()\n        array[i,:]=data\n        i += 1\n    return array","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train negative\ntrain_negative_path = r\"../input/lsifir/LSIFIR/Classification/Train/neg\"\nnum_train_negative_img = 43390\ntrain_negative_array = read_images(train_negative_path, num_train_negative_img)\n\nx_train_negative_tensor = torch.from_numpy(train_negative_array)\nprint(\"x_train_negative_tensor : \",x_train_negative_tensor.size())\ny_train_negative_tensor = torch.zeros(num_train_negative_img, dtype = torch.long)\nprint(\"y_train_negative_tensor : \", y_train_negative_tensor.size())","execution_count":3,"outputs":[{"output_type":"stream","text":"x_train_negative_tensor :  torch.Size([43390, 2048])\ny_train_negative_tensor :  torch.Size([43390])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train positive\ntrain_positive_path = r\"../input/lsifir/LSIFIR/Classification/Train/pos\"\nnum_train_positive_img = 10208\ntrain_positive_array = read_images(train_positive_path,num_train_positive_img)\n\nx_train_positive_tensor = torch.from_numpy(train_positive_array)\nprint(\"x_train_positive_tensor : \",x_train_negative_tensor.size())\ny_train_positive_tensor = torch.zeros(num_train_negative_img, dtype = torch.long)\nprint(\"y_train_positive_tensor : \", y_train_positive_tensor.size())","execution_count":4,"outputs":[{"output_type":"stream","text":"x_train_positive_tensor :  torch.Size([43390, 2048])\ny_train_positive_tensor :  torch.Size([43390])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train concat\nx_train = torch.cat((x_train_negative_tensor, x_train_positive_tensor),0)\ny_train = torch.cat((y_train_negative_tensor, y_train_positive_tensor),0)\nprint(\"x_train : \", x_train.size())\nprint(\"y_train : \", y_train.size())","execution_count":5,"outputs":[{"output_type":"stream","text":"x_train :  torch.Size([53598, 2048])\ny_train :  torch.Size([86780])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test negative\ntest_negative_path = r\"../input/lsifir/LSIFIR/Classification/Test/neg\"\nnum_test_negative_img = 22050\ntest_negative_array = read_images(test_negative_path,num_test_negative_img)\n\nx_test_negative_tensor = torch.from_numpy(test_negative_array[:20855,:])\nprint(\"x_test_negative_tensor : \",x_test_negative_tensor.size())\ny_test_negative_tensor = torch.zeros(20855, dtype = torch.long)\nprint(\"y_test_negative_tensor : \", y_test_negative_tensor.size())","execution_count":6,"outputs":[{"output_type":"stream","text":"x_test_negative_tensor :  torch.Size([20855, 2048])\ny_test_negative_tensor :  torch.Size([20855])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test positive\ntest_positive_path = r\"../input/lsifir/LSIFIR/Classification/Test/pos\"\nnum_test_positive_img = 5944\ntest_positive_array = read_images(test_positive_path,num_test_positive_img)\n\nx_test_positive_tensor = torch.from_numpy(test_positive_array)\nprint(\"x_test_positive_tensor : \",x_test_negative_tensor.size())\ny_test_positive_tensor = torch.zeros(num_test_negative_img, dtype = torch.long)\nprint(\"y_test_positive_tensor : \", y_test_positive_tensor.size())","execution_count":7,"outputs":[{"output_type":"stream","text":"x_test_positive_tensor :  torch.Size([20855, 2048])\ny_test_positive_tensor :  torch.Size([22050])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#concat test\nx_test = torch.cat((x_test_negative_tensor, x_test_positive_tensor),0)\ny_test = torch.cat((y_test_negative_tensor, y_test_positive_tensor),0)\nprint(\"x_test : \", x_test.size())\nprint(\"y_test : \", y_test.size())","execution_count":8,"outputs":[{"output_type":"stream","text":"x_test :  torch.Size([26799, 2048])\ny_test :  torch.Size([42905])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CNN Hyperparameters\n\nnum_epochs = 5000\nnum_class = 2\nbatch_size = 8933\nlearning_rate = 0.00001","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(n.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        self.conv1 = n.Conv2d(1,10,5)\n        self.pool = n.MaxPool2d(2,2)\n        self.conv2 = n.Conv2d(10,16,5)\n        self.fc1 = n.Linear(16*13*5,520)\n        self.fc2 = n.Linear(520,130)\n        self.fc3 = n.Linear(130,num_class)\n        \n        \n    def forward(self,x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        \n        x = x.view(-1,16*13*5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = torch.utils.data.TensorDataset(x_train[:53598,:2048], y_train[:53598])\ntrainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle = True)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = torch.utils.data.TensorDataset(x_test[:26799, :2048], y_test[:26799])\ntestloader = torch.utils.data.DataLoader(test, batch_size, shuffle = False)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net()","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = n.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(),lr=learning_rate, momentum = 0.8)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\ntrain_acc = []\ntest_acc = []\nloss_list = []\n\nfor epoch in range(num_epochs):\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        inputs = inputs.view(batch_size,1,64,32)\n        inputs = inputs.float()\n        \n        #zero graient\n        optimizer.zero_grad()\n        \n        #forward\n        outputs = net(inputs)\n        \n        #loos\n        loss = criterion(outputs,labels)\n        \n        #back\n        loss.backward()\n        \n        #update weights\n        optimizer.step()\n        \n    #test\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images.view(batch_size,1,64,32)\n            images = images.float()\n            \n            outputs = net(images)\n            _,predicted = torch.max(outputs.data,1)\n            \n            total += labels.size(0)\n            \n            correct += (predicted == labels).sum().item()\n    \n    acc1 = 100*correct/total\n    print(\"accuracy test : \", acc1)\n    \n    test_acc.append(acc1)\n    \n    #train\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in trainloader:\n            images, labels = data\n            images.view(batch_size,1,64,32)\n            images = images.float()\n            \n            outputs = net(images)\n            _,predicted = torch.max(outputs.data,1)\n            \n            total += labels.size(0)\n            \n            correct += (predicted == labels).sum().item()\n    \n    acc2 = 100*correct/total\n    print(\"accuracy train : \", acc2)\n    \n    train_acc.append(acc2)\n    \nprint(\"train is done\")\n        \n        \n\n\n#train\n\n\n\n\n\nend = time.time()\nprocess_time = (end-start)/60\nprint(\"Process Time : \",process_time)","execution_count":16,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'view' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-9d6aaa608746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'view' is not defined"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}